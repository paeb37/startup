# startup Dexter (gpt-5 hackathon)

Minimal ASP.NET Core API for parsing PowerPoint decks into structured JSON and rendering slide previews as PDF for the secure knowledge base prototype.

## Prerequisites
- .NET 9 SDK (`dotnet --version`)
- Python 3.10+ (`python3 --version`) for the Flask instruction parser
- LibreOffice (`soffice`) available on `PATH` or via `SOFFICE_PATH` if you plan to use `/api/render`

## Run the API
```bash
dotnet restore apps/api-dotnet/Dexter.WebApi.csproj
dotnet run --project apps/api-dotnet/Dexter.WebApi.csproj
```

The default launch profile exposes `http://localhost:5100`.

## Configuration
`apps/api-dotnet/Properties/launchSettings.json` seeds local environment variables:
- `applicationUrl`: `http://localhost:5100`
- `SEMANTIC_URL`: `http://localhost:8000` (placeholder for future semantic services)
- `SOFFICE_PATH`: `/Applications/LibreOffice.app/Contents/MacOS/soffice`
- `SUPABASE_URL`: base URL of your Supabase instance (e.g. `https://abc.supabase.co`)
- `SUPABASE_SERVICE_ROLE_KEY`: service role API key used for inserts
- `SUPABASE_STORAGE_BUCKET`: Supabase Storage bucket name for deck assets (e.g. `decks`)
- `SUPABASE_STORAGE_PREFIX`: optional folder prefix inside the bucket (defaults to none)
- `OPENAI_API_KEY`: key used for embeddings, image captions, and table summaries
- `OPENAI_EMBEDDING_MODEL`: embedding model name (defaults to `text-embedding-3-small`)
- `OPENAI_VISION_MODEL`: OpenAI Responses model for vision/text summaries (defaults to `gpt-4o-mini`)
- `SUPABASE_DECKS_TABLE`: override for the decks table name (defaults to `decks`)
- `SUPABASE_SLIDES_TABLE`: override for the slides table name (defaults to `slides`)

Override any value before running if your setup differs:

```bash
export SOFFICE_PATH=/usr/local/bin/soffice
dotnet run --project apps/api-dotnet/Dexter.WebApi.csproj
```

## Endpoints
- `POST /api/upload` — accepts multipart field `file` (optional `instructions`); uploads the PPTX/JSON/PDF bundle to Supabase Storage and returns deck JSON alongside a base64-encoded PDF preview.
- `POST /api/render` — accepts multipart field `file`, converts the deck to PDF for inline viewing; requires LibreOffice. (Primarily kept for tooling—`/api/upload` already returns the PDF.)

### Supabase schema

Enable the `vector` extension once, then create the tables expected by `/api/upload`:

```sql
create extension if not exists vector;

create table if not exists decks (
  id uuid primary key,
  deck_name text not null,
  pptx_path text not null,
  redacted_pptx_path text,
  redacted_pdf_path text,
  redacted_json_path text,
  slide_count integer not null,
  created_at timestamptz not null default timezone('utc', now()),
  updated_at timestamptz not null default timezone('utc', now())
);

create table if not exists slides (
  id uuid primary key,
  deck_id uuid references decks(id) on delete cascade,
  slide_no integer not null,
  embedding vector(1536),
  created_at timestamptz not null default timezone('utc', now()),
  updated_at timestamptz not null default timezone('utc', now())
);

create index if not exists slides_deck_id_slide_no_idx on slides(deck_id, slide_no);
create index if not exists slides_embedding_idx on slides using ivfflat (embedding vector_l2_ops) with (lists = 100);
```

The `pptx_path` column stores the original upload, while the `redacted_*` columns point at the sanitized artifacts generated by `/api/decks/{id}/redact`. Each value is the object path inside your Supabase Storage bucket (e.g. `my-prefix/3f0c1f2a9d5b4e42ac0cf5c9a6382a8a/deck-redacted.pdf`). Keep the bucket name itself in `SUPABASE_STORAGE_BUCKET`.

When `OPENAI_API_KEY` is set the upload pipeline generates per-image summaries (stored on each picture element) and per-table summaries (stored on each table element) before creating the slide embeddings.

Grant your service role access to both tables, or configure Supabase Row Level Security policies as needed for your workflow.

### Instruction Parser (Flask)
```bash
cd apps/python-semantic
python3 -m venv .venv
source .venv/bin/activate   # .venv\Scripts\activate on Windows
pip install -r requirements.txt
FLASK_APP=app.py flask run --host 0.0.0.0 --port 8000 --debug
```

### Quick test
```bash
curl -H "Accept: application/json" \
     -F "file=@/absolute/path/to/deck.pptx" \
     http://localhost:5100/api/upload

curl -H "Accept: application/json" \
     -F "file=@/absolute/path/to/deck.pptx" \
     -F "instructions=Redact client names and revenue" \
     http://localhost:5100/api/upload
```

Example response:

```json
{
  "file": "deck.pptx",
  "slideCount": 17,
  "slides": [...]
}
```

## Repo layout
```
apps/
└─ api-dotnet/
   ├─ Dexter.WebApi.csproj
   ├─ Program.cs
   └─ Properties/
      └─ launchSettings.json
tools/
└─ converter/
   ├─ Dockerfile
   └─ server.py
```

## Local startup
1. Start the warm LibreOffice converter (runs on port 5019 by default):
   ```bash
   cd tools
   docker-compose up lo-converter
   ```

2. In another terminal, launch the .NET API (it will call the converter via `LIBRE_CONVERTER_URL`, defaulting to `http://127.0.0.1:5019`):
   ```bash
   dotnet run --project apps/api-dotnet/Dexter.WebApi.csproj
   ```

3. (Optional) Start the Python semantic service:
   ```bash
   cd apps/python-semantic
   pip install -r requirements.txt
   FLASK_APP=app.py flask run --host 0.0.0.0 --port 8000 --debug
   ```

## Troubleshooting
- Converter container down → conversion falls back to local LibreOffice and slows to ~8s; check `docker compose ps` in `tools/`.
- LibreOffice missing locally → fallback path `/api/render` returns 501; install LibreOffice or set `SOFFICE_PATH`.
- Port collision → update `applicationUrl` in `launchSettings.json`.
- CORS is wide open for local prototyping; tighten before shipping.
